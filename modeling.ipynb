{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "from transformers.models.qwen2.modeling_qwen2 import apply_rotary_pos_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/src/quiet-star/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-270M\", torch_dtype=torch.float32, trust_remote_code=True)\n",
    "pretrained_config = AutoConfig.from_pretrained(\"apple/OpenELM-270M\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenELMConfig {\n",
       "  \"_name_or_path\": \"apple/OpenELM-270M\",\n",
       "  \"activation_fn_name\": \"swish\",\n",
       "  \"architectures\": [\n",
       "    \"OpenELMForCausalLM\"\n",
       "  ],\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"apple/OpenELM-270M--configuration_openelm.OpenELMConfig\",\n",
       "    \"AutoModelForCausalLM\": \"apple/OpenELM-270M--modeling_openelm.OpenELMForCausalLM\"\n",
       "  },\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim_divisor\": 256,\n",
       "  \"ffn_multipliers\": [\n",
       "    0.5,\n",
       "    0.73,\n",
       "    0.97,\n",
       "    1.2,\n",
       "    1.43,\n",
       "    1.67,\n",
       "    1.9,\n",
       "    2.13,\n",
       "    2.37,\n",
       "    2.6,\n",
       "    2.83,\n",
       "    3.07,\n",
       "    3.3,\n",
       "    3.53,\n",
       "    3.77,\n",
       "    4.0\n",
       "  ],\n",
       "  \"ffn_with_glu\": true,\n",
       "  \"head_dim\": 64,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_context_length\": 2048,\n",
       "  \"model_dim\": 1280,\n",
       "  \"model_type\": \"openelm\",\n",
       "  \"normalization_layer_name\": \"rms_norm\",\n",
       "  \"normalize_qk_projections\": true,\n",
       "  \"num_gqa_groups\": 4,\n",
       "  \"num_kv_heads\": [\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    4,\n",
       "    4,\n",
       "    4,\n",
       "    4,\n",
       "    4,\n",
       "    4,\n",
       "    4,\n",
       "    5,\n",
       "    5,\n",
       "    5,\n",
       "    5\n",
       "  ],\n",
       "  \"num_query_heads\": [\n",
       "    12,\n",
       "    12,\n",
       "    12,\n",
       "    12,\n",
       "    12,\n",
       "    16,\n",
       "    16,\n",
       "    16,\n",
       "    16,\n",
       "    16,\n",
       "    16,\n",
       "    16,\n",
       "    20,\n",
       "    20,\n",
       "    20,\n",
       "    20\n",
       "  ],\n",
       "  \"num_transformer_layers\": 16,\n",
       "  \"qkv_multipliers\": [\n",
       "    0.5,\n",
       "    1.0\n",
       "  ],\n",
       "  \"rope_freq_constant\": 10000,\n",
       "  \"rope_max_length\": 4096,\n",
       "  \"share_input_output_layers\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.40.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'attn',\n",
       " 'attn_norm',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'ffn',\n",
       " 'ffn_norm',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = dict(model.named_modules())\n",
    "dir(modules[\"transformer.layers\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'transformer',\n",
       " 'transformer.token_embeddings',\n",
       " 'transformer.layers',\n",
       " 'transformer.layers.0',\n",
       " 'transformer.layers.0.attn',\n",
       " 'transformer.layers.0.attn.qkv_proj',\n",
       " 'transformer.layers.0.attn.pos_embedding',\n",
       " 'transformer.layers.0.attn.q_norm',\n",
       " 'transformer.layers.0.attn.k_norm',\n",
       " 'transformer.layers.0.attn.out_proj',\n",
       " 'transformer.layers.0.ffn',\n",
       " 'transformer.layers.0.ffn.proj_1',\n",
       " 'transformer.layers.0.ffn.proj_2',\n",
       " 'transformer.layers.0.ffn.act',\n",
       " 'transformer.layers.0.ffn_norm',\n",
       " 'transformer.layers.0.attn_norm',\n",
       " 'transformer.layers.1',\n",
       " 'transformer.layers.1.attn',\n",
       " 'transformer.layers.1.attn.qkv_proj',\n",
       " 'transformer.layers.1.attn.pos_embedding',\n",
       " 'transformer.layers.1.attn.q_norm',\n",
       " 'transformer.layers.1.attn.k_norm',\n",
       " 'transformer.layers.1.attn.out_proj',\n",
       " 'transformer.layers.1.ffn',\n",
       " 'transformer.layers.1.ffn.proj_1',\n",
       " 'transformer.layers.1.ffn.proj_2',\n",
       " 'transformer.layers.1.ffn.act',\n",
       " 'transformer.layers.1.ffn_norm',\n",
       " 'transformer.layers.1.attn_norm',\n",
       " 'transformer.layers.2',\n",
       " 'transformer.layers.2.attn',\n",
       " 'transformer.layers.2.attn.qkv_proj',\n",
       " 'transformer.layers.2.attn.pos_embedding',\n",
       " 'transformer.layers.2.attn.q_norm',\n",
       " 'transformer.layers.2.attn.k_norm',\n",
       " 'transformer.layers.2.attn.out_proj',\n",
       " 'transformer.layers.2.ffn',\n",
       " 'transformer.layers.2.ffn.proj_1',\n",
       " 'transformer.layers.2.ffn.proj_2',\n",
       " 'transformer.layers.2.ffn.act',\n",
       " 'transformer.layers.2.ffn_norm',\n",
       " 'transformer.layers.2.attn_norm',\n",
       " 'transformer.layers.3',\n",
       " 'transformer.layers.3.attn',\n",
       " 'transformer.layers.3.attn.qkv_proj',\n",
       " 'transformer.layers.3.attn.pos_embedding',\n",
       " 'transformer.layers.3.attn.q_norm',\n",
       " 'transformer.layers.3.attn.k_norm',\n",
       " 'transformer.layers.3.attn.out_proj',\n",
       " 'transformer.layers.3.ffn',\n",
       " 'transformer.layers.3.ffn.proj_1',\n",
       " 'transformer.layers.3.ffn.proj_2',\n",
       " 'transformer.layers.3.ffn.act',\n",
       " 'transformer.layers.3.ffn_norm',\n",
       " 'transformer.layers.3.attn_norm',\n",
       " 'transformer.layers.4',\n",
       " 'transformer.layers.4.attn',\n",
       " 'transformer.layers.4.attn.qkv_proj',\n",
       " 'transformer.layers.4.attn.pos_embedding',\n",
       " 'transformer.layers.4.attn.q_norm',\n",
       " 'transformer.layers.4.attn.k_norm',\n",
       " 'transformer.layers.4.attn.out_proj',\n",
       " 'transformer.layers.4.ffn',\n",
       " 'transformer.layers.4.ffn.proj_1',\n",
       " 'transformer.layers.4.ffn.proj_2',\n",
       " 'transformer.layers.4.ffn.act',\n",
       " 'transformer.layers.4.ffn_norm',\n",
       " 'transformer.layers.4.attn_norm',\n",
       " 'transformer.layers.5',\n",
       " 'transformer.layers.5.attn',\n",
       " 'transformer.layers.5.attn.qkv_proj',\n",
       " 'transformer.layers.5.attn.pos_embedding',\n",
       " 'transformer.layers.5.attn.q_norm',\n",
       " 'transformer.layers.5.attn.k_norm',\n",
       " 'transformer.layers.5.attn.out_proj',\n",
       " 'transformer.layers.5.ffn',\n",
       " 'transformer.layers.5.ffn.proj_1',\n",
       " 'transformer.layers.5.ffn.proj_2',\n",
       " 'transformer.layers.5.ffn.act',\n",
       " 'transformer.layers.5.ffn_norm',\n",
       " 'transformer.layers.5.attn_norm',\n",
       " 'transformer.layers.6',\n",
       " 'transformer.layers.6.attn',\n",
       " 'transformer.layers.6.attn.qkv_proj',\n",
       " 'transformer.layers.6.attn.pos_embedding',\n",
       " 'transformer.layers.6.attn.q_norm',\n",
       " 'transformer.layers.6.attn.k_norm',\n",
       " 'transformer.layers.6.attn.out_proj',\n",
       " 'transformer.layers.6.ffn',\n",
       " 'transformer.layers.6.ffn.proj_1',\n",
       " 'transformer.layers.6.ffn.proj_2',\n",
       " 'transformer.layers.6.ffn.act',\n",
       " 'transformer.layers.6.ffn_norm',\n",
       " 'transformer.layers.6.attn_norm',\n",
       " 'transformer.layers.7',\n",
       " 'transformer.layers.7.attn',\n",
       " 'transformer.layers.7.attn.qkv_proj',\n",
       " 'transformer.layers.7.attn.pos_embedding',\n",
       " 'transformer.layers.7.attn.q_norm',\n",
       " 'transformer.layers.7.attn.k_norm',\n",
       " 'transformer.layers.7.attn.out_proj',\n",
       " 'transformer.layers.7.ffn',\n",
       " 'transformer.layers.7.ffn.proj_1',\n",
       " 'transformer.layers.7.ffn.proj_2',\n",
       " 'transformer.layers.7.ffn.act',\n",
       " 'transformer.layers.7.ffn_norm',\n",
       " 'transformer.layers.7.attn_norm',\n",
       " 'transformer.layers.8',\n",
       " 'transformer.layers.8.attn',\n",
       " 'transformer.layers.8.attn.qkv_proj',\n",
       " 'transformer.layers.8.attn.pos_embedding',\n",
       " 'transformer.layers.8.attn.q_norm',\n",
       " 'transformer.layers.8.attn.k_norm',\n",
       " 'transformer.layers.8.attn.out_proj',\n",
       " 'transformer.layers.8.ffn',\n",
       " 'transformer.layers.8.ffn.proj_1',\n",
       " 'transformer.layers.8.ffn.proj_2',\n",
       " 'transformer.layers.8.ffn.act',\n",
       " 'transformer.layers.8.ffn_norm',\n",
       " 'transformer.layers.8.attn_norm',\n",
       " 'transformer.layers.9',\n",
       " 'transformer.layers.9.attn',\n",
       " 'transformer.layers.9.attn.qkv_proj',\n",
       " 'transformer.layers.9.attn.pos_embedding',\n",
       " 'transformer.layers.9.attn.q_norm',\n",
       " 'transformer.layers.9.attn.k_norm',\n",
       " 'transformer.layers.9.attn.out_proj',\n",
       " 'transformer.layers.9.ffn',\n",
       " 'transformer.layers.9.ffn.proj_1',\n",
       " 'transformer.layers.9.ffn.proj_2',\n",
       " 'transformer.layers.9.ffn.act',\n",
       " 'transformer.layers.9.ffn_norm',\n",
       " 'transformer.layers.9.attn_norm',\n",
       " 'transformer.layers.10',\n",
       " 'transformer.layers.10.attn',\n",
       " 'transformer.layers.10.attn.qkv_proj',\n",
       " 'transformer.layers.10.attn.pos_embedding',\n",
       " 'transformer.layers.10.attn.q_norm',\n",
       " 'transformer.layers.10.attn.k_norm',\n",
       " 'transformer.layers.10.attn.out_proj',\n",
       " 'transformer.layers.10.ffn',\n",
       " 'transformer.layers.10.ffn.proj_1',\n",
       " 'transformer.layers.10.ffn.proj_2',\n",
       " 'transformer.layers.10.ffn.act',\n",
       " 'transformer.layers.10.ffn_norm',\n",
       " 'transformer.layers.10.attn_norm',\n",
       " 'transformer.layers.11',\n",
       " 'transformer.layers.11.attn',\n",
       " 'transformer.layers.11.attn.qkv_proj',\n",
       " 'transformer.layers.11.attn.pos_embedding',\n",
       " 'transformer.layers.11.attn.q_norm',\n",
       " 'transformer.layers.11.attn.k_norm',\n",
       " 'transformer.layers.11.attn.out_proj',\n",
       " 'transformer.layers.11.ffn',\n",
       " 'transformer.layers.11.ffn.proj_1',\n",
       " 'transformer.layers.11.ffn.proj_2',\n",
       " 'transformer.layers.11.ffn.act',\n",
       " 'transformer.layers.11.ffn_norm',\n",
       " 'transformer.layers.11.attn_norm',\n",
       " 'transformer.layers.12',\n",
       " 'transformer.layers.12.attn',\n",
       " 'transformer.layers.12.attn.qkv_proj',\n",
       " 'transformer.layers.12.attn.pos_embedding',\n",
       " 'transformer.layers.12.attn.q_norm',\n",
       " 'transformer.layers.12.attn.k_norm',\n",
       " 'transformer.layers.12.attn.out_proj',\n",
       " 'transformer.layers.12.ffn',\n",
       " 'transformer.layers.12.ffn.proj_1',\n",
       " 'transformer.layers.12.ffn.proj_2',\n",
       " 'transformer.layers.12.ffn.act',\n",
       " 'transformer.layers.12.ffn_norm',\n",
       " 'transformer.layers.12.attn_norm',\n",
       " 'transformer.layers.13',\n",
       " 'transformer.layers.13.attn',\n",
       " 'transformer.layers.13.attn.qkv_proj',\n",
       " 'transformer.layers.13.attn.pos_embedding',\n",
       " 'transformer.layers.13.attn.q_norm',\n",
       " 'transformer.layers.13.attn.k_norm',\n",
       " 'transformer.layers.13.attn.out_proj',\n",
       " 'transformer.layers.13.ffn',\n",
       " 'transformer.layers.13.ffn.proj_1',\n",
       " 'transformer.layers.13.ffn.proj_2',\n",
       " 'transformer.layers.13.ffn.act',\n",
       " 'transformer.layers.13.ffn_norm',\n",
       " 'transformer.layers.13.attn_norm',\n",
       " 'transformer.layers.14',\n",
       " 'transformer.layers.14.attn',\n",
       " 'transformer.layers.14.attn.qkv_proj',\n",
       " 'transformer.layers.14.attn.pos_embedding',\n",
       " 'transformer.layers.14.attn.q_norm',\n",
       " 'transformer.layers.14.attn.k_norm',\n",
       " 'transformer.layers.14.attn.out_proj',\n",
       " 'transformer.layers.14.ffn',\n",
       " 'transformer.layers.14.ffn.proj_1',\n",
       " 'transformer.layers.14.ffn.proj_2',\n",
       " 'transformer.layers.14.ffn.act',\n",
       " 'transformer.layers.14.ffn_norm',\n",
       " 'transformer.layers.14.attn_norm',\n",
       " 'transformer.layers.15',\n",
       " 'transformer.layers.15.attn',\n",
       " 'transformer.layers.15.attn.qkv_proj',\n",
       " 'transformer.layers.15.attn.pos_embedding',\n",
       " 'transformer.layers.15.attn.q_norm',\n",
       " 'transformer.layers.15.attn.k_norm',\n",
       " 'transformer.layers.15.attn.out_proj',\n",
       " 'transformer.layers.15.ffn',\n",
       " 'transformer.layers.15.ffn.proj_1',\n",
       " 'transformer.layers.15.ffn.proj_2',\n",
       " 'transformer.layers.15.ffn.act',\n",
       " 'transformer.layers.15.ffn_norm',\n",
       " 'transformer.layers.15.attn_norm',\n",
       " 'transformer.norm']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict(model.named_modules()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers_modules.apple.OpenELM-270M.945fb18d02b1c4c81d7989e80b7564c6d91e8300.modeling_openelm.OpenELMForCausalLM"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = dict(model.named_modules())\n",
    "tok_emb = modules[\"transformer.token_embeddings\"]\n",
    "tok_emb.num_embeddings, tok_emb.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings().embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/src/quiet-star/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\", torch_dtype=torch.float32, trust_remote_code=True)\n",
    "pretrained_config = AutoConfig.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_name_or_path\": \"Qwen/Qwen2-0.5B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151645,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 896,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4864,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 24,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 14,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": 32768,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151936, 1024])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings().weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([151936, 1024])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[\"model.embed_tokens\"].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_assisted_decoding',\n",
       " '_auto_class',\n",
       " '_autoset_attn_implementation',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_beam_sample',\n",
       " '_beam_search',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_check_and_enable_sdpa',\n",
       " '_constrained_beam_search',\n",
       " '_contrastive_search',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_candidate_generator',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_no_split_modules',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_greedy_search',\n",
       " '_group_beam_search',\n",
       " '_has_unfinished_sequences',\n",
       " '_hf_peft_config_loaded',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_is_quantized_training_enabled',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_generation_config',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_sample',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_supports_cache_class',\n",
       " '_supports_flash_attn_2',\n",
       " '_supports_sdpa',\n",
       " '_temporary_reorder_cache',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_model_tags',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'assisted_decoding',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_decoder',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'lm_head',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'model',\n",
       " 'model_tags',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_decoder',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'vocab_size',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.container.ModuleList"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = dict(model.named_modules())\n",
    "i = 0\n",
    "q_proj = modules[f\"model.layers.{i}.self_attn.q_proj\"]\n",
    "k_proj = modules[f\"model.layers.{i}.self_attn.k_proj\"]\n",
    "v_proj = modules[f\"model.layers.{i}.self_attn.v_proj\"]\n",
    "o_proj = modules[f\"model.layers.{i}.self_attn.o_proj\"]\n",
    "layers = modules[f\"model.layers\"]\n",
    "type(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 64]), torch.Size([7, 64]), 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.full((2, 3, 5, layers[0].self_attn.head_dim), 1.2, dtype=torch.float32)\n",
    "cos, sin = layers[0].self_attn.rotary_emb(v, seq_len=7)\n",
    "cos.shape, sin.shape, layers[0].self_attn.head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 2, 3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 2\n",
    "L = 6\n",
    "D = 4\n",
    "a = torch.arange(0, L, dtype=torch.int64)\n",
    "b = torch.arange(0, D, dtype=torch.int64)\n",
    "# position_ids = a.reshape(1, L) + b.reshape(D, 1)\n",
    "position_ids = a.unsqueeze(0).tile((B, 1))\n",
    "print(position_ids)\n",
    "cos[position_ids].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 6\n",
    "position_ids = torch.arange(\n",
    "    0, L, dtype=torch.long\n",
    ")\n",
    "position_ids = position_ids.unsqueeze(0).view(-1, L)\n",
    "position_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 6, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = 3\n",
    "q = torch.full((B, H, L, layers[0].self_attn.head_dim), 1.2, dtype=torch.float32)\n",
    "q_embed = (q * cos[position_ids].unsqueeze(1)) + (rotate_half(q) * sin[position_ids].unsqueeze(1))\n",
    "q_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['', 'model', 'model.embed_tokens', 'model.layers', 'model.layers.0', 'model.layers.0.self_attn', 'model.layers.0.self_attn.q_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.0.self_attn.o_proj', 'model.layers.0.self_attn.rotary_emb', 'model.layers.0.mlp', 'model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.0.mlp.act_fn', 'model.layers.0.input_layernorm', 'model.layers.0.post_attention_layernorm', 'model.layers.1', 'model.layers.1.self_attn', 'model.layers.1.self_attn.q_proj', 'model.layers.1.self_attn.k_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.1.self_attn.rotary_emb', 'model.layers.1.mlp', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.1.mlp.act_fn', 'model.layers.1.input_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.2', 'model.layers.2.self_attn', 'model.layers.2.self_attn.q_proj', 'model.layers.2.self_attn.k_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.2.self_attn.o_proj', 'model.layers.2.self_attn.rotary_emb', 'model.layers.2.mlp', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.2.mlp.act_fn', 'model.layers.2.input_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.3', 'model.layers.3.self_attn', 'model.layers.3.self_attn.q_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.3.self_attn.o_proj', 'model.layers.3.self_attn.rotary_emb', 'model.layers.3.mlp', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj', 'model.layers.3.mlp.act_fn', 'model.layers.3.input_layernorm', 'model.layers.3.post_attention_layernorm', 'model.layers.4', 'model.layers.4.self_attn', 'model.layers.4.self_attn.q_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.4.self_attn.v_proj', 'model.layers.4.self_attn.o_proj', 'model.layers.4.self_attn.rotary_emb', 'model.layers.4.mlp', 'model.layers.4.mlp.gate_proj', 'model.layers.4.mlp.up_proj', 'model.layers.4.mlp.down_proj', 'model.layers.4.mlp.act_fn', 'model.layers.4.input_layernorm', 'model.layers.4.post_attention_layernorm', 'model.layers.5', 'model.layers.5.self_attn', 'model.layers.5.self_attn.q_proj', 'model.layers.5.self_attn.k_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.5.self_attn.rotary_emb', 'model.layers.5.mlp', 'model.layers.5.mlp.gate_proj', 'model.layers.5.mlp.up_proj', 'model.layers.5.mlp.down_proj', 'model.layers.5.mlp.act_fn', 'model.layers.5.input_layernorm', 'model.layers.5.post_attention_layernorm', 'model.layers.6', 'model.layers.6.self_attn', 'model.layers.6.self_attn.q_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.6.self_attn.v_proj', 'model.layers.6.self_attn.o_proj', 'model.layers.6.self_attn.rotary_emb', 'model.layers.6.mlp', 'model.layers.6.mlp.gate_proj', 'model.layers.6.mlp.up_proj', 'model.layers.6.mlp.down_proj', 'model.layers.6.mlp.act_fn', 'model.layers.6.input_layernorm', 'model.layers.6.post_attention_layernorm', 'model.layers.7', 'model.layers.7.self_attn', 'model.layers.7.self_attn.q_proj', 'model.layers.7.self_attn.k_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.7.self_attn.rotary_emb', 'model.layers.7.mlp', 'model.layers.7.mlp.gate_proj', 'model.layers.7.mlp.up_proj', 'model.layers.7.mlp.down_proj', 'model.layers.7.mlp.act_fn', 'model.layers.7.input_layernorm', 'model.layers.7.post_attention_layernorm', 'model.layers.8', 'model.layers.8.self_attn', 'model.layers.8.self_attn.q_proj', 'model.layers.8.self_attn.k_proj', 'model.layers.8.self_attn.v_proj', 'model.layers.8.self_attn.o_proj', 'model.layers.8.self_attn.rotary_emb', 'model.layers.8.mlp', 'model.layers.8.mlp.gate_proj', 'model.layers.8.mlp.up_proj', 'model.layers.8.mlp.down_proj', 'model.layers.8.mlp.act_fn', 'model.layers.8.input_layernorm', 'model.layers.8.post_attention_layernorm', 'model.layers.9', 'model.layers.9.self_attn', 'model.layers.9.self_attn.q_proj', 'model.layers.9.self_attn.k_proj', 'model.layers.9.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.9.self_attn.rotary_emb', 'model.layers.9.mlp', 'model.layers.9.mlp.gate_proj', 'model.layers.9.mlp.up_proj', 'model.layers.9.mlp.down_proj', 'model.layers.9.mlp.act_fn', 'model.layers.9.input_layernorm', 'model.layers.9.post_attention_layernorm', 'model.layers.10', 'model.layers.10.self_attn', 'model.layers.10.self_attn.q_proj', 'model.layers.10.self_attn.k_proj', 'model.layers.10.self_attn.v_proj', 'model.layers.10.self_attn.o_proj', 'model.layers.10.self_attn.rotary_emb', 'model.layers.10.mlp', 'model.layers.10.mlp.gate_proj', 'model.layers.10.mlp.up_proj', 'model.layers.10.mlp.down_proj', 'model.layers.10.mlp.act_fn', 'model.layers.10.input_layernorm', 'model.layers.10.post_attention_layernorm', 'model.layers.11', 'model.layers.11.self_attn', 'model.layers.11.self_attn.q_proj', 'model.layers.11.self_attn.k_proj', 'model.layers.11.self_attn.v_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.11.self_attn.rotary_emb', 'model.layers.11.mlp', 'model.layers.11.mlp.gate_proj', 'model.layers.11.mlp.up_proj', 'model.layers.11.mlp.down_proj', 'model.layers.11.mlp.act_fn', 'model.layers.11.input_layernorm', 'model.layers.11.post_attention_layernorm', 'model.layers.12', 'model.layers.12.self_attn', 'model.layers.12.self_attn.q_proj', 'model.layers.12.self_attn.k_proj', 'model.layers.12.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.12.self_attn.rotary_emb', 'model.layers.12.mlp', 'model.layers.12.mlp.gate_proj', 'model.layers.12.mlp.up_proj', 'model.layers.12.mlp.down_proj', 'model.layers.12.mlp.act_fn', 'model.layers.12.input_layernorm', 'model.layers.12.post_attention_layernorm', 'model.layers.13', 'model.layers.13.self_attn', 'model.layers.13.self_attn.q_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.13.self_attn.v_proj', 'model.layers.13.self_attn.o_proj', 'model.layers.13.self_attn.rotary_emb', 'model.layers.13.mlp', 'model.layers.13.mlp.gate_proj', 'model.layers.13.mlp.up_proj', 'model.layers.13.mlp.down_proj', 'model.layers.13.mlp.act_fn', 'model.layers.13.input_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.14', 'model.layers.14.self_attn', 'model.layers.14.self_attn.q_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.14.self_attn.rotary_emb', 'model.layers.14.mlp', 'model.layers.14.mlp.gate_proj', 'model.layers.14.mlp.up_proj', 'model.layers.14.mlp.down_proj', 'model.layers.14.mlp.act_fn', 'model.layers.14.input_layernorm', 'model.layers.14.post_attention_layernorm', 'model.layers.15', 'model.layers.15.self_attn', 'model.layers.15.self_attn.q_proj', 'model.layers.15.self_attn.k_proj', 'model.layers.15.self_attn.v_proj', 'model.layers.15.self_attn.o_proj', 'model.layers.15.self_attn.rotary_emb', 'model.layers.15.mlp', 'model.layers.15.mlp.gate_proj', 'model.layers.15.mlp.up_proj', 'model.layers.15.mlp.down_proj', 'model.layers.15.mlp.act_fn', 'model.layers.15.input_layernorm', 'model.layers.15.post_attention_layernorm', 'model.layers.16', 'model.layers.16.self_attn', 'model.layers.16.self_attn.q_proj', 'model.layers.16.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.16.self_attn.o_proj', 'model.layers.16.self_attn.rotary_emb', 'model.layers.16.mlp', 'model.layers.16.mlp.gate_proj', 'model.layers.16.mlp.up_proj', 'model.layers.16.mlp.down_proj', 'model.layers.16.mlp.act_fn', 'model.layers.16.input_layernorm', 'model.layers.16.post_attention_layernorm', 'model.layers.17', 'model.layers.17.self_attn', 'model.layers.17.self_attn.q_proj', 'model.layers.17.self_attn.k_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.17.self_attn.o_proj', 'model.layers.17.self_attn.rotary_emb', 'model.layers.17.mlp', 'model.layers.17.mlp.gate_proj', 'model.layers.17.mlp.up_proj', 'model.layers.17.mlp.down_proj', 'model.layers.17.mlp.act_fn', 'model.layers.17.input_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.18', 'model.layers.18.self_attn', 'model.layers.18.self_attn.q_proj', 'model.layers.18.self_attn.k_proj', 'model.layers.18.self_attn.v_proj', 'model.layers.18.self_attn.o_proj', 'model.layers.18.self_attn.rotary_emb', 'model.layers.18.mlp', 'model.layers.18.mlp.gate_proj', 'model.layers.18.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.18.mlp.act_fn', 'model.layers.18.input_layernorm', 'model.layers.18.post_attention_layernorm', 'model.layers.19', 'model.layers.19.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.19.self_attn.k_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.19.self_attn.rotary_emb', 'model.layers.19.mlp', 'model.layers.19.mlp.gate_proj', 'model.layers.19.mlp.up_proj', 'model.layers.19.mlp.down_proj', 'model.layers.19.mlp.act_fn', 'model.layers.19.input_layernorm', 'model.layers.19.post_attention_layernorm', 'model.layers.20', 'model.layers.20.self_attn', 'model.layers.20.self_attn.q_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.20.self_attn.v_proj', 'model.layers.20.self_attn.o_proj', 'model.layers.20.self_attn.rotary_emb', 'model.layers.20.mlp', 'model.layers.20.mlp.gate_proj', 'model.layers.20.mlp.up_proj', 'model.layers.20.mlp.down_proj', 'model.layers.20.mlp.act_fn', 'model.layers.20.input_layernorm', 'model.layers.20.post_attention_layernorm', 'model.layers.21', 'model.layers.21.self_attn', 'model.layers.21.self_attn.q_proj', 'model.layers.21.self_attn.k_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.self_attn.o_proj', 'model.layers.21.self_attn.rotary_emb', 'model.layers.21.mlp', 'model.layers.21.mlp.gate_proj', 'model.layers.21.mlp.up_proj', 'model.layers.21.mlp.down_proj', 'model.layers.21.mlp.act_fn', 'model.layers.21.input_layernorm', 'model.layers.21.post_attention_layernorm', 'model.layers.22', 'model.layers.22.self_attn', 'model.layers.22.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.22.self_attn.v_proj', 'model.layers.22.self_attn.o_proj', 'model.layers.22.self_attn.rotary_emb', 'model.layers.22.mlp', 'model.layers.22.mlp.gate_proj', 'model.layers.22.mlp.up_proj', 'model.layers.22.mlp.down_proj', 'model.layers.22.mlp.act_fn', 'model.layers.22.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.23', 'model.layers.23.self_attn', 'model.layers.23.self_attn.q_proj', 'model.layers.23.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.23.self_attn.rotary_emb', 'model.layers.23.mlp', 'model.layers.23.mlp.gate_proj', 'model.layers.23.mlp.up_proj', 'model.layers.23.mlp.down_proj', 'model.layers.23.mlp.act_fn', 'model.layers.23.input_layernorm', 'model.layers.23.post_attention_layernorm', 'model.norm', 'lm_head'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = {name: module for name, module in model.named_modules()}\n",
    "modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  750,  1173, 38217,  1445,   982,   256,  3190,   256,  8213,   678,\n",
       "         49433,  1948,   220,    16,   323,   308,   198,   256,  4210]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[  3.6836,  -1.1255,   1.5150,  ...,   2.6303,  -0.5123,   1.7374],\n",
       "         [  7.4853,  -0.9902,  -4.0687,  ...,   1.7265,   0.2599,  -1.1351],\n",
       "         [ 24.2062,  -7.2295,   4.1781,  ...,   9.3780,  -1.2049,  -6.5320],\n",
       "         ...,\n",
       "         [ -5.0436,   1.9755,  -3.9743,  ...,   1.4521,   1.5901,   6.1949],\n",
       "         [ -0.9378,   4.4864,  -1.1898,  ...,   4.1787,  -2.2388,  -4.0903],\n",
       "         [-10.6983,  -3.1012,  -4.7337,  ...,   3.5523,  -4.2465,   0.8423]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = modules[\"model\"](inputs[\"input_ids\"]).last_hidden_state\n",
    "print(hidden.shape)\n",
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 151936])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4811, -6.1711, -6.3514,  ..., -8.3448, -8.3446, -8.3446],\n",
       "         [-2.9108,  1.6906, -3.2120,  ..., -6.1205, -6.1200, -6.1203],\n",
       "         [ 3.0356,  3.6571,  2.9795,  ..., -4.3870, -4.3862, -4.3864],\n",
       "         ...,\n",
       "         [ 9.9981, 10.2735, 11.2037,  ..., -3.3791, -3.3778, -3.3788],\n",
       "         [-0.9505, -2.4659, -2.6616,  ..., -4.5804, -4.5799, -4.5798],\n",
       "         [ 8.5299,  7.0447, 13.8696,  ..., -1.6405, -1.6392, -1.6405]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = modules[\"lm_head\"](hidden)\n",
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_thoughts(token_ids: torch.Tensor, thought_tokens: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    In parallel across `n` tokens, generate `thought_tokens` tokens resulting in\n",
    "    `n x (3 + thought_tokens)` total tokens including the <|startofthought|> and\n",
    "    <|endofthought|> tokens.\n",
    "    \"\"\"\n",
    "    for t in range(thought_tokens):\n",
    "        # Naive attention computation:\n",
    "        # evaluate the model on the unraveled sequence of tokens\n",
    "        # position embeddings: [p_0 ... p_l p_1 ... p_{l + 1} p_2 ... p_{l + 2}]\n",
    "        # query, key, value: (b, (t + 1) x l, e)\n",
    "        # special attention mask\n",
    "        # only need last l predictions\n",
    "\n",
    "        # Optimized attention computation:\n",
    "        # position embeddings: [p_0 ... p_l p_1 ... p_{l + 1} p_2 ... p_{l + 2}]\n",
    "        # new attention weights: original seq (b, l, e), t^th thought tokens (b, l, e)\n",
    "        # new diagonal attention weigths:\n",
    "        #   thought tokens (b, t + 1, l, e), t^th thought tokens (b, 1, l, e) => (b, t + 1, l)\n",
    "        # form full attention weight tensor (b, t + 2, l, l)\n",
    "        # softmax of weights\n",
    "        # linear combination of values (b, t + 2, l, e)\n",
    "        # output (b, l, e)\n",
    "\n",
    "        # custom attention weight calculation\n",
    "        # traditional multi-head attention calculation where K != V using custom attn weights\n",
    "        # attention(sparse_attn_weights, values)\n",
    "        # can still use flash attention trick to tile matrices and calculate in SRAM\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = dd.read_json(\"hf://datasets/allenai/c4/en/c4-train.00000-of-01024.json.gz\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55397"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_parquet(\"hf://datasets/open-web-math/open-web-math/data/train-00000-of-00114-5a023365406cb9c4.parquet\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.loc[0][\"text\"].compute()\n",
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes and hisTheorem\n",
      "\n",
      "My earlier post on Bayesian probability seems to have generated quite a lot of readers, so this lunchtime I thought Id add a little bit of background. The previous discussion started from the result\n",
      "\n",
      "$P(B|AC) = K^{-1}P(B|C)P(A|BC) = K^{-1} P(AB|C)$\n",
      "\n",
      "where\n",
      "\n",
      "$K=P(A|C).$\n",
      "\n",
      "Although this is called Bayes theorem, the general form of it as stated here was actually first written down, not by Bayes but by Laplace. What Bayes did was derive the special case of this formula for inverting the binomial distribution. This distribution gives the probability of x successes in n independent trials each having the same probability of success, p; each trial has only two possible outcomes (success or failure). Trials like this are usually called Bernoulli trials, after Daniel Bernoulli. If we ask the question what is the probability of exactly x successes from the possible n?, the answer is given by the binomial distribution:\n",
      "\n",
      "$P_n(x|n,p)= C(n,x) p^x (1-p)^{n-x}$\n",
      "\n",
      "where\n",
      "\n",
      "$C(n,x)= n!/x!(n-x)!$\n",
      "\n",
      "is the number of distinct combinations of x objects that can be drawn from a pool of n.\n",
      "\n",
      "You can probably see immediately how this arises. The probability of x consecutive successes is p multiplied by itself x times, or px. The probability of (n-x) successive failures is similarly (1-p)n-x. The last two terms basically therefore tell us the probability that we have exactly x successes (since there must be n-x failures). The combinatorial factor in front takes account of the fact that the ordering of successes and failures doesnt matter.\n",
      "\n",
      "The binomial distribution applies, for example, to repeated tosses of a coin, in which case p is taken to be 0.5 for a fair coin. A biased coin might have a different value of p, but as long as the tosses are independent the formula still applies. The binomial distribution also applies to problems involving drawing balls from urns: it works exactly if the balls are replaced in the urn after each draw, but it also applies approximately without replacement, as long as the number of draws is much smaller than the number of balls in the urn. I leave it as an exercise to calculate the expectation value of the binomial distribution, but the result is not surprising: E(X)=np. If you toss a fair coin ten times the expectation value for the number of heads is 10 times 0.5, which is five. No surprise there. After another bit of maths, the variance of the distribution can also be found. It is np(1-p).\n",
      "\n",
      "So this gives us the probability of x given a fixed value of p. Bayes was interested in the inverse of this result, the probability of p given x. In other words, Bayes was interested in the answer to the question If I perform n independent trials and get x successes, what is the probability distribution of p?. This is a classic example of inverse reasoning. He got the correct answer, eventually, but by very convoluted reasoning. In my opinion it is quite difficult to justify the name Bayes theorem based on what he actually did, although Laplace did specifically acknowledge this contribution when he derived the general result later, which is no doubt why the theorem is always named in Bayes honour.\n",
      "\n",
      "This is not the only example in science where the wrong persons name is attached to a result or discovery. In fact, it is almost a law of Nature that any theorem that has a name has the wrong name. I propose that this observation should henceforth be known as Coles Law.\n",
      "\n",
      "So who was the mysterious mathematician behind this result? Thomas Bayes was born in 1702, son of Joshua Bayes, who was a Fellow of the Royal Society (FRS) and one of the very first nonconformist ministers to be ordained in England. Thomas was himself ordained and for a while worked with his father in the Presbyterian Meeting House in Leather Lane, near Holborn in London. In 1720 he was a minister in Tunbridge Wells, in Kent. He retired from the church in 1752 and died in 1761. Thomas Bayes didnt publish a single paper on mathematics in his own name during his lifetime but despite this was elected a Fellow of the Royal Society (FRS) in 1742. Presumably he had Friends of the Right Sort. He did however write a paper on fluxions in 1736, which was published anonymously. This was probably the grounds on which he was elected an FRS.\n",
      "\n",
      "The paper containing the theorem that now bears his name was published posthumously in the Philosophical Transactions of the Royal Society of London in 1764.\n",
      "\n",
      "P.S. I understand that the authenticity of the picture is open to question. Whoever it actually is, he looks to me a bit like Laurence Olivier\n",
      "\n",
      "11 Responses to Bayes and hisTheorem\n",
      "\n",
      "1. Bryn Jones Says:\n",
      "\n",
      "The Royal Society is providing free access to electronic versions of its journals until the end of this month. Readers of this blog might like to look at Thomas Bayess two posthumous publications in the Philosophical Transactions.\n",
      "\n",
      "The first is a short paper about series. The other is the paper about statistics communicated by Richard Price. (The statistics paper may be accessible on a long-term basis because it is one of the Royal Societys Trailblazing papers the society provides access to as part of its 350th anniversary celebrations.)\n",
      "\n",
      "Incidentally, both Thomas Bayes and Richard Price were buried in the Bunhill Fields Cemetery in London and their tombs can be seen there today.\n",
      "\n",
      "2. Steve Warren Says:\n",
      "\n",
      "You may be remembered in history as the discoverer of coleslaw, but you werent the first.\n",
      "\n",
      " Anton Garrett Says:\n",
      "\n",
      "For years I thought it was cold slaw because it was served cold. A good job I never asked for warm slaw.\n",
      "\n",
      "3. telescoper Says:\n",
      "\n",
      "My surname, in Spanish, means Cabbages. So it was probably one of my ancestors who invented the chopped variety.\n",
      "\n",
      "4. Anton Garrett Says:\n",
      "\n",
      "Thomas Bayes is now known to have gone to Edinburgh University, where his name appears in the records. He was barred from English universities because his nonconformist family did not have him baptised in the Church of England. (Charles Darwins nonconformist family covered their bets by having baby Charles baptised in the CoE, although perhaps they believed it didnt count as a baptism since Charles had no say in it. Tist is why he was able to go to Christs College, Cambridge.)\n",
      "\n",
      "5. Cole is an old English word for cabbage, which survives in cole slaw. The German word is Kohl. (Somehow, I dont see PM or President Cabbage being a realistic possibility.  )\n",
      "\n",
      "Note that Old King Cole is unrelated (etymologically). Of course, this discussion could cause Peter to post a clip of\n",
      "\n",
      "Nat King Cole\n",
      "(guess what his real surname is).\n",
      "\n",
      "To remind people to pay attention to spelling when they hear words, well close with the Quote of the Day:\n",
      "\n",
      "Its important to pay close attention in school. For years I thought that\n",
      "bears masturbated all winter.\n",
      "\n",
      "Damon R. Milhem\n",
      "\n",
      "6. Of course, this discussion could cause Peter to post a clip of\n",
      "Nat King Cole\n",
      "(giess what his real surname is).\n",
      "\n",
      "7. Of course, this discussion could cause Peter to post a clip of\n",
      "Nat King Cole\n",
      "(giess what his real surname is).\n",
      "\n",
      "The first typo was my fault; the extra linebreaks in the second attempt\n",
      "(tested again here) appear to be a new feature.\n",
      "\n",
      "8. telescoper Says:\n",
      "\n",
      "The noun cole can be found in English dictionaries as a generic name for plants of the cabbage family. It is related to the German kohl and scottish kail or kale. These are all derived from the latin word colis (or caulis) meaning a stem, which is also the root of the word cauliflower.\n",
      "\n",
      "The surname Cole and the variant Coles are fairly common in England and Wales, but are not related to the latin word for cabbage. Both are diminutives of the name Nicholas.\n",
      "\n",
      "9. [] I posted a little piece about Bayesian probability. That one and the others that followed it (here and here) proved to be surprisingly popular so Ive been planning to add a few more posts []\n",
      "\n",
      "10. It already has a popular name: Stiglers law of eponymy.\n"
     ]
    }
   ],
   "source": [
    "print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"open-web-math/open-web-math\",\n",
    "    data_files={\"train\": [\"data/train-00000-of-00114-5a023365406cb9c4.parquet\"],},\n",
    "    num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_split_on_whitespace(text: str, min_remaining_whitespace: int = 256) -> str:\n",
    "    \"\"\"\n",
    "    Splits a string on a random whitespace character and returns the second part.\n",
    "\n",
    "    Args:\n",
    "        text: The string to split.\n",
    "        min_remaining_whitespace: The minimum number of whitespace characters to leave in string.\n",
    "\n",
    "    Returns:\n",
    "        The second part of the string after a random whitespace split, \n",
    "        or the original string if no whitespace is found.\n",
    "        Leading whitespace is stripped.\n",
    "    \"\"\"\n",
    "    whitespace_indexes = [i for i, char in enumerate(text) if char.isspace()][:-min_remaining_whitespace]\n",
    "\n",
    "    if not whitespace_indexes:\n",
    "        return text  # Not enough whitespace found, return original text\n",
    "\n",
    "    random_index = random.choice(whitespace_indexes)\n",
    "\n",
    "    return text[random_index + 1:].lstrip()\n",
    "\n",
    "\n",
    "def process_batch(examples: dict[str, list]) -> dict[str, list]:\n",
    "    result = {\n",
    "        \"input_ids\": [\n",
    "            tokenizer(random_split_on_whitespace(text, 256), max_length=256, truncation=True)[\"input_ids\"]\n",
    "            for text in examples[\"text\"]\n",
    "        ],\n",
    "    }\n",
    "    result[\"text\"] = tokenizer.batch_decode(result[\"input_ids\"])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a084f33d6174e709df90d76458a117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/55397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_dataset.save_to_disk(\"data/open-web-math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019e2b29a3c545a688639ac38849c05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_dataset = train_dataset[\"train\"].select(range(100)).map(\n",
    "    process_batch, batched=True, remove_columns=[\"url\", \"date\", \"metadata\"],\n",
    ")\n",
    "small_dataset.set_format(\"np\", columns=[\"input_ids\"], output_all_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "np_dataset = datasets.load_from_disk(\"data/open-web-math\")\n",
    "type(np_dataset[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([12555,   374,   279, 18927,  7982,   315,   281,    30, 11204,\n",
       "         1096,   374,   264, 11416,  3110,   315, 27949, 32711,    13,\n",
       "         1260,  2684,   279,  4396,  4226,    11,  9583,    11,   714,\n",
       "          553,  1602,  5686,   337,  2774, 32711,    13,   758,   847,\n",
       "         9459,   432,   374,  5008,  5000,   311,  9357,   279,   829,\n",
       "         9154,   288,   527, 57817,  3118,   389,  1128,   566,  3520,\n",
       "         1521,    11,  7892, 49055, 26536,  1521, 11689, 24645,   419,\n",
       "        18527,   979,   566, 14257,   279,  4586,  1102,  2937,    11,\n",
       "          892,   374,   902, 10492,  3170,   279, 57817,   374,  2677,\n",
       "         6941,   304,  9154,   288,   527, 33562,   382,  1986,   374,\n",
       "          537,   279,  1172,  3110,   304,  8038,  1380,   279,  4969,\n",
       "         1697,   748,   829,   374, 12392,   311,   264,  1102,   476,\n",
       "        18335,    13,   758,  2097,    11,   432,   374,  4558,   264,\n",
       "         2329,   315, 21331,   429,   894, 57817,   429,   702,   264,\n",
       "          829,   702,   279,  4969,   829,    13,   358, 29614,   429,\n",
       "          419, 21930,  1265, 16085, 70527,   387,  3881,   438,  3539,\n",
       "          642,   527,  7506,   382,  4416,   879,   572,   279, 25382,\n",
       "        20976,  1103,  4815,   419,  1102,    30, 11108,  9154,   288,\n",
       "          572,  9223,   304,   220,    16,    22,    15,    17,    11,\n",
       "         4438,   315, 39492,  9154,   288,    11,   879,   572,   264,\n",
       "        36846,   315,   279, 16194, 13278,   320, 10504,    50,     8,\n",
       "          323,   825,   315,   279,  1602,  1156,  2477,   443,   627,\n",
       "          380, 33950,   311,   387, 85624,   304,  9448,    13, 11108,\n",
       "          572,  5561, 85624,   323,   369,   264,  1393,  6439,   448,\n",
       "          806,  6981,   304,   279, 85364, 29055,  4678,   304, 31078,\n",
       "        26018,    11,  3143, 15696, 15998,   304,  7148,    13,   758,\n",
       "          220,    16,    22,    17,    15,   566,   572,   264, 12725,\n",
       "          304, 27456, 13709, 36858,    11,   304, 17734,    13,  1260,\n",
       "        21583,   504,   279,  8817]),\n",
       " 'text': 'what is the probability distribution of p?. This is a classic example of inverse reasoning. He got the correct answer, eventually, but by very convoluted reasoning. In my opinion it is quite difficult to justify the name Bayes theorem based on what he actually did, although Laplace did specifically acknowledge this contribution when he derived the general result later, which is no doubt why the theorem is always named in Bayes honour.\\n\\nThis is not the only example in science where the wrong persons name is attached to a result or discovery. In fact, it is almost a law of Nature that any theorem that has a name has the wrong name. I propose that this observation should henceforth be known as Coles Law.\\n\\nSo who was the mysterious mathematician behind this result? Thomas Bayes was born in 1702, son of Joshua Bayes, who was a Fellow of the Royal Society (FRS) and one of the very first nonconformist ministers to be ordained in England. Thomas was himself ordained and for a while worked with his father in the Presbyterian Meeting House in Leather Lane, near Holborn in London. In 1720 he was a minister in Tunbridge Wells, in Kent. He retired from the church'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 1055,   419, 14806,   369,  1036,   258, 49417,   854,   279,\n",
       "         9544, 20855,  7982,    13,  1096,  7982,  6696,   279, 18927,\n",
       "          315,   856, 47088,   304,   308,  9489,  1036,   376, 10309,\n",
       "          854,  1817,  3432,   279,  1852, 18927,   315,  2393,    11,\n",
       "          281,    26,  1817,  1036, 47347,   854,   702,  1172,  1378,\n",
       "         3204, 19554, 26087,  5630,   854,   476,  1036, 28939, 64212,\n",
       "        69444,  1075,   419,   525,  5990,  2598, 14168,   283, 39976,\n",
       "        19080,    11,  1283, 15118, 14168,   283, 39976,    13,  1416,\n",
       "          582,  2548,   279,  3405,  1036, 12555,   374,   279, 18927,\n",
       "          315,  6896,   856, 47088,   504,   279,  3204,   308,    30,\n",
       "         9336,   279,  4226,   374,  2661,   553,   279,  9544, 20855,\n",
       "         7982,  1447,     3,    47,  1089,  2075,    91,    77,  7237,\n",
       "        11730,   356,  1445, 12803,     8,   281,    61,    87,   320,\n",
       "           16,  2268, 29776,    90,    77,  6558, 31716,   271,  2870,\n",
       "          271,     3,    34,  1445, 12803, 11730,   308, 87980,    87,\n",
       "        10297,    77,  6558, 41295, 66426,   285,   279,  1372,   315,\n",
       "        12460, 27459,   315,   856,  6171,   429,   646,   387, 14764,\n",
       "          504,   264,  7314,   315,   308,   382,  2610,   646,  4658,\n",
       "         1490,  7069,  1246,   419, 47182,    13,   576, 18927,   315,\n",
       "          856, 23921, 47088,   374,   281, 54916,   553,  5086,   856,\n",
       "         3039,    11,   476, 17146,    13,   576, 18927,   315,   320,\n",
       "           77,  6558,     8, 48924, 27850,   374, 29193,   320,    16,\n",
       "         2268, 79098,  6558,    13,   576,  1537,  1378,  3793, 13221,\n",
       "         8916,  3291,   601,   279, 18927,   429,   582,   614,  6896,\n",
       "          856, 47088,   320, 11284,  1052,  1969,   387,   308,  6558,\n",
       "        27850,   568,   576,  3614, 17272,   530,  8168,   304,  4065,\n",
       "         4990,  2692,   315,   279,  2097,   429,   279, 21391,   315,\n",
       "        47088,   323, 27850,  3171,  1405,  4925,   382,   785,  9544,\n",
       "        20855,  7982, 16790,    11]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\"Bayes and his Theorem\n",
    "\n",
    "My earlier post on Bayesian probability seems to have generated quite a lot of readers, so this lunchtime I thought Id add a little bit of background. The previous discussion started from the result\n",
    "\n",
    "$P(B|AC) = K^{-1}P(B|C)P(A|BC) = K^{-1} P(AB|C)$\n",
    "\n",
    "where\n",
    "\n",
    "$K=P(A|C).$\n",
    "\n",
    "Although this is called Bayes theorem, the general form of it as stated here was actually first written down, not by Bayes but by Laplace. What Bayes did was derive the special case of this formula for inverting the binomial distribution. This distribution gives the probability of x successes in n independent trials each having the same probability of success, p; each trial has only two possible outcomes (success or failure). Trials like this are usually called Bernoulli trials, after Daniel Bernoulli. If we ask the question what is the probability of exactly x successes from the possible n?, the answer is given by the binomial distribution:\n",
    "\n",
    "$P_n(x|n,p)= C(n,x) p^x (1-p)^{n-x}$\n",
    "\n",
    "where\n",
    "\n",
    "$C(n,x)= n!/x!(n-x)!$\n",
    "\n",
    "is the number of distinct combinations of x objects that can be drawn from a pool of n.\n",
    "\n",
    "You can probably see immediately how this arises. The probability of x consecutive successes is p multiplied by itself x times, or px. The probability of (n-x) successive failures is similarly (1-p)n-x. The last two terms basically therefore tell us the probability that we have exactly x successes (since there must be n-x failures). The combinatorial factor in front takes account of the fact that the ordering of successes and failures doesnt matter.\n",
    "\n",
    "The binomial distribution applies, for example, to repeated tosses of a coin, in which case p is taken to be 0.5 for a fair coin. A biased coin might have a different value of p, but as long as the tosses are independent the formula still applies. The binomial distribution also applies to problems involving drawing balls from urns: it works exactly if the balls are replaced in the urn after each draw, but it also applies approximately without replacement, as long as the number of draws is much smaller than the number of balls in the urn. I leave it as an exercise to calculate the expectation value of the binomial distribution, but the result is not surprising: E(X)=np. If you toss a fair coin ten times the expectation value for the number of heads is 10 times 0.5, which is five. No surprise there. After another bit of maths, the variance of the distribution can also be found. It is np(1-p).\n",
    "\n",
    "So this gives us the probability of x given a fixed value of p. Bayes was interested in the inverse of this result, the probability of p given x. In other words, Bayes was interested in the answer to the question If I perform n independent trials and get x successes, what is the probability distribution of p?. This is a classic example of inverse reasoning. He got the correct answer, eventually, but by very convoluted reasoning. In my opinion it is quite difficult to justify the name Bayes theorem based on what he actually did, although Laplace did specifically acknowledge this contribution when he derived the general result later, which is no doubt why the theorem is always named in Bayes honour.\n",
    "...\n",
    "\n",
    "9. [] I posted a little piece about Bayesian probability. That one and the others that followed it (here and here) proved to be surprisingly popular so Ive been planning to add a few more posts []\n",
    "\n",
    "10. It already has a popular name: Stiglers law of eponymy.\n",
    "\"\"\"\n",
    "tokenizer(random_split_on_whitespace(s), return_tensors=\"np\", max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4421])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_dash_ids = tokenizer(\"---\", return_tensors=\"pt\", return_attention_mask=False)[\"input_ids\"][0]\n",
    "em_dash_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 2 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Qwen2ForCausalLM.get_input_embeddings of Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151648, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151648, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\n",
    "    \"additional_special_tokens\": [\n",
    "        \"<|startofthought|>\",\n",
    "        \"<|endofthought|>\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print(\"We have added\", num_added_toks, \"tokens\")\n",
    "\n",
    "# Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e., the length of the tokenizer.\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0171, -0.0122,  0.0055,  ...,  0.0212,  0.0002, -0.0220])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.get_input_embeddings()\n",
    "init_token_embedding = embeddings.weight[em_dash_ids].detach()\n",
    "init_token_embedding.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlayers\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"Qwen/Qwen1.5-0.5B\")\n",
    "config.tie_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_name_or_path\": \"Qwen/Qwen1.5-0.5B\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151643,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2816,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": 32768,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config.to_json_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings.weight[-2] = init_token_embedding\n",
    "    embeddings.weight[-1] = init_token_embedding\n",
    "    model.set_input_embeddings(embeddings)\n",
    "    model.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_dataset[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import dataclasses\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import lightning as L\n",
    "import lightning.pytorch\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import HfFileSystem\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class QuietStarConfig:\n",
    "    batch_size: int = 1\n",
    "    dtype: torch.dtype = torch.float32\n",
    "    learning_rate: float = 1e-3\n",
    "    max_length: int = 256\n",
    "    model_name: str = \"Qwen/Qwen1.5-0.5B\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "class QuietStarModel(L.LightningModule):\n",
    "    def __init__(self, config: QuietStarConfig):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(config.model_name, torch_dtype=config.dtype, trust_remote_code=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "        self.tokenizer.add_special_tokens({\n",
    "            \"additional_special_tokens\": [\n",
    "                \"<|startofthought|>\",\n",
    "                \"<|endofthought|>\",\n",
    "            ],\n",
    "        })\n",
    "\n",
    "        # resize_token_embeddings expects to receive the full size of the new vocabulary\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        # initialize the new tokens to use the average of the embeddings of the tokenized string \"---\"\n",
    "        em_dash_ids = self.tokenizer(\"---\", return_tensors=\"pt\", return_attention_mask=False)[\"input_ids\"][0]\n",
    "        em_dash_ids\n",
    "\n",
    "        embeddings = self.model.get_input_embeddings()\n",
    "        init_token_embedding = embeddings.weight[em_dash_ids].detach()\n",
    "        init_token_embedding = init_token_embedding.mean(dim=0)\n",
    "\n",
    "        model_config = AutoConfig.from_pretrained(\"Qwen/Qwen1.5-0.5B\")\n",
    "        with torch.no_grad():\n",
    "            embeddings.weight[-2] = init_token_embedding\n",
    "            embeddings.weight[-1] = init_token_embedding\n",
    "            self.model.set_input_embeddings(embeddings)\n",
    "            if model_config.tie_word_embeddings:\n",
    "                self.model.tie_weights()\n",
    "\n",
    "        self.learning_rate = config.learning_rate\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        output = self.model(input_ids[:, :-1], labels=input_ids[:, 1:])\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        loss, logits = self(input_ids)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "def random_split_on_whitespace(text: str, min_remaining_whitespace: int = 256) -> str:\n",
    "    \"\"\"\n",
    "    Splits a string on a random whitespace character and returns the second part.\n",
    "\n",
    "    Args:\n",
    "        text: The string to split.\n",
    "        min_remaining_whitespace: The minimum number of whitespace characters to leave in string.\n",
    "\n",
    "    Returns:\n",
    "        The second part of the string after a random whitespace split, \n",
    "        or the original string if no whitespace is found.\n",
    "        Leading whitespace is stripped.\n",
    "    \"\"\"\n",
    "    whitespace_indexes = [i for i, char in enumerate(text) if char.isspace()][:-min_remaining_whitespace]\n",
    "\n",
    "    if not whitespace_indexes:\n",
    "        return text  # Not enough whitespace found, return original text\n",
    "\n",
    "    random_index = random.choice(whitespace_indexes)\n",
    "\n",
    "    return text[random_index + 1:].lstrip()\n",
    "\n",
    "\n",
    "def process_batch(tokenizer: AutoTokenizer, max_length: int = 256) -> Callable[[dict[str, list]], dict[str, list]]:\n",
    "    def _process(examples: dict[str, list]) -> dict[str, list]:\n",
    "        result = {\n",
    "            \"input_ids\": [\n",
    "                tokenizer(random_split_on_whitespace(text, max_length + 1), max_length=max_length + 1, truncation=True)[\"input_ids\"]\n",
    "                for text in examples[\"text\"]\n",
    "            ],\n",
    "        }\n",
    "        result[\"text\"] = tokenizer.batch_decode(result[\"input_ids\"])\n",
    "        return result\n",
    "    \n",
    "    return _process\n",
    "\n",
    "config = QuietStarConfig(\n",
    "    batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    max_length=8,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "lightning.pytorch.seed_everything(config.seed, workers=True)\n",
    "\n",
    "model = QuietStarModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24390d882e1e41c3bb14673f32ff0cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acb9493358a46a8b8687c51eac4123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = HfFileSystem()\n",
    "\n",
    "# List all \".parquet\" files in the repo\n",
    "paths = fs.glob(\"datasets/open-web-math/open-web-math/**/*.parquet\")\n",
    "relative_paths = [\n",
    "    str(pathlib.Path(path).relative_to(*pathlib.Path(path).parts[:3]))\n",
    "    for path in paths\n",
    "]\n",
    "\n",
    "large_dataset = load_dataset(\n",
    "    \"open-web-math/open-web-math\",\n",
    "    data_files={\"train\": relative_paths[:1]},\n",
    "    num_proc=8,\n",
    ")\n",
    "\n",
    "small_dataset = large_dataset[\"train\"].select(range(256)).map(\n",
    "    process_batch(model.tokenizer, config.max_length),\n",
    "    batched=True,\n",
    "    remove_columns=[\"url\", \"date\", \"metadata\"],\n",
    ")\n",
    "small_dataset = small_dataset.remove_columns(\"text\")\n",
    "small_dataset.set_format(\"pt\", columns=[\"input_ids\"], output_all_columns=True)\n",
    "small_dataset.save_to_disk(\"data/open-web-math\")\n",
    "\n",
    "del large_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ds = small_dataset.train_test_split(test_size=0.125, shuffle=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(ds[\"train\"], batch_size=config.batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(ds[\"test\"], batch_size=config.batch_size)\n",
    "\n",
    "trainer = lightning.pytorch.Trainer(deterministic=True, accelerator=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/directml/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "/home/user/miniconda3/envs/directml/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | Qwen2ForCausalLM | 463 M \n",
      "-------------------------------------------\n",
      "463 M     Trainable params\n",
      "0         Non-trainable params\n",
      "463 M     Total params\n",
      "1,854.771 Total estimated model params size (MB)\n",
      "/home/user/miniconda3/envs/directml/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d81d4ba7e94eb398794def48adee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_ids'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
